---
phase: 05-claude-summarization
plan: 02
type: tdd
wave: 2
depends_on: ["05-01"]
files_modified:
  - src/services/summarization.service.ts
  - src/services/__tests__/summarization.service.test.ts
autonomous: true

must_haves:
  truths:
    - "Transcripts under 50K tokens are processed as a single request"
    - "Transcripts over 50K tokens are split into chunks with 10% overlap and map-reduced"
    - "Cost estimation accurately calculates per-video and batch costs with 10% buffer"
    - "Long transcript summaries maintain coherence across chunk boundaries (no missing or duplicated content)"
  artifacts:
    - path: "src/services/summarization.service.ts"
      provides: "Chunking logic, cost estimation, map-reduce orchestration"
      exports: ["splitIntoChunks", "estimateCost", "estimateBatchCost", "summarizeVideo"]
    - path: "src/services/__tests__/summarization.service.test.ts"
      provides: "Tests for chunking, cost estimation, and orchestration"
      min_lines: 80
  key_links:
    - from: "src/services/summarization.service.ts"
      to: "src/services/claude.service.ts"
      via: "import summarizeTranscript, countTranscriptTokens"
      pattern: "import.*claude\\.service"
    - from: "src/services/summarization.service.ts"
      to: "src/types/summary.ts"
      via: "import types and constants"
      pattern: "import.*summary"
---

<objective>
Build the summarization orchestration service using TDD: chunking logic for long transcripts (map-reduce with overlap), cost estimation for batch processing, and the main summarizeVideo function that decides whether to chunk.

Purpose: This is the core intelligence layer -- it handles the blocking concern from STATE.md about long videos (50K-150K tokens) and provides accurate cost estimation for user consent before processing.
Output: Tested summarization service with chunking, cost estimation, and video-level orchestration.
</objective>

<execution_context>
@/Users/nathanstasin/.claude/get-shit-done/workflows/execute-plan.md
@/Users/nathanstasin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-claude-summarization/05-RESEARCH.md
@.planning/phases/05-claude-summarization/05-01-SUMMARY.md

@src/services/claude.service.ts
@src/types/summary.ts
@src/services/__tests__/transcript.service.test.ts
</context>

<feature>
  <name>Summarization Service: Chunking + Cost Estimation</name>
  <files>src/services/summarization.service.ts, src/services/__tests__/summarization.service.test.ts</files>
  <behavior>
    **splitIntoChunks(text, chunkSize, overlapPercent)**
    - Input: text string, chunkSize in words (default 9000 words ~= 12K tokens), overlapPercent (default 0.10)
    - Output: string[] of chunks
    - Cases:
      - Short text (100 words) -> [full text] (single chunk)
      - Medium text (15K words) -> [chunk1, chunk2] with overlap
      - Long text (40K words) -> [chunk1, chunk2, chunk3, chunk4, chunk5] with 10% word overlap
      - Empty text -> [""] (single empty chunk)
      - Overlap: last 10% of chunk N appears at start of chunk N+1
      - Never splits mid-word (splits on whitespace boundaries)

    **estimateCost(inputTokens)**
    - Input: number of input tokens
    - Output: { inputCost, outputCost, totalCost, totalWithBuffer }
    - Cases:
      - 1000 tokens -> inputCost = 0.003, outputCost = 0.06144, totalCost = 0.06444, totalWithBuffer = 0.070884
      - 100000 tokens -> inputCost = 0.3, outputCost = 0.06144, totalCost = 0.36144, totalWithBuffer = 0.397584
      - Cost formula: input = (tokens / 1M) * $3, output = (MAX_OUTPUT_TOKENS / 1M) * $15
      - Buffer: totalCost * 1.10 (10% buffer)
      - Chunked transcripts: multiply output cost by estimated chunk count

    **estimateBatchCost(transcriptTokenCounts: Map&lt;string, number&gt;)**
    - Input: Map of videoId -> inputTokens
    - Output: BatchCostEstimate with per-video estimates, totals, chunking info
    - Determines which videos need chunking (> CHUNK_TOKEN_THRESHOLD)
    - Sums up all per-video estimates

    **summarizeVideo(transcript, apiKey)**
    - If transcript token count < CHUNK_TOKEN_THRESHOLD: call summarizeTranscript directly
    - If transcript token count >= CHUNK_TOKEN_THRESHOLD: split into chunks, map-summarize each chunk, reduce into final summary
    - Returns: { summary, cost, inputTokens, outputTokens, wasChunked }
    - The map step uses plain text summarization (not structured output) per chunk
    - The reduce step sends all chunk summaries to Claude with the structured output prompt
  </behavior>
  <implementation>
    Create `src/services/summarization.service.ts` with:

    1. `splitIntoChunks(text: string, chunkSize?: number, overlapPercent?: number): string[]`
       - Default chunkSize = 9000 words (~12K tokens at ~1.33 tokens/word)
       - Default overlapPercent = 0.10
       - Split on whitespace, group into chunks with overlap
       - Return array of chunk strings

    2. `estimateCost(inputTokens: number, chunkCount?: number): CostBreakdown`
       - Use constants from summary.ts (INPUT_PRICE_PER_MTOK, OUTPUT_PRICE_PER_MTOK, MAX_OUTPUT_TOKENS)
       - If chunkCount > 1, multiply output cost by (chunkCount + 1) -- one per chunk map + one reduce
       - Apply COST_BUFFER_PERCENT

    3. `estimateBatchCost(transcriptTokenCounts: Map<string, number>): BatchCostEstimate`
       - Iterate over Map, estimate per-video cost
       - Flag videos needing chunking
       - Sum totals

    4. `summarizeVideo(transcript: string, apiKey: string): Promise<SummarizeVideoResult>`
       - Count tokens via countTranscriptTokens
       - If under threshold, call summarizeTranscript directly
       - If over threshold:
         a. Split transcript into chunks with splitIntoChunks
         b. MAP: For each chunk, call summarizeTranscript with a simplified prompt (chunk summary, not full structured output). Actually, use the same Edge Function but the prompt will be different -- pass the chunk text to summarizeTranscript which already calls the proxy. For the map step, since we want plain text chunk summaries, we need a separate function `summarizeChunk(chunk, index, total, apiKey)` that calls the proxy with action 'summarize-chunk' (or just uses the same summarize action but with a different prompt).

         SIMPLIFICATION: For MVP, use the same `/api/summarize` endpoint but have the client pass a `mode` field: 'full' for structured output, 'chunk' for plain text chunk summary. The Edge Function switches system prompt based on mode. Add `mode?: 'full' | 'chunk'` to the request body.

         c. REDUCE: Concatenate chunk summaries, send as single structured summary request
       - Return result with wasChunked flag

    Mock `claude.service.ts` functions in tests using vitest mocking. Test the pure functions (splitIntoChunks, estimateCost) directly without mocks.

    **Test Implementation Task:** After writing the source file, create `src/services/__tests__/summarization.service.test.ts` with the following test cases using vitest:

    - `splitIntoChunks`: short text (100 words) returns single chunk, medium text (15K words) returns 2 chunks with overlap, long text (40K words) returns 5 chunks, empty text returns single empty chunk, chunks never split mid-word (verify no chunk starts/ends with partial word)
    - `estimateCost`: 1000 tokens produces correct cost breakdown (inputCost=0.003, outputCost=0.06144, total with 10% buffer), 100000 tokens calculation, chunked transcript multiplies output cost by (chunkCount+1)
    - `estimateBatchCost`: mixed Map of small and large transcripts, verifies per-video estimates, totals, and videosNeedingChunking count
    - `summarizeVideo`: mock countTranscriptTokens to return value under threshold -> verify summarizeTranscript called directly, mock to return over threshold -> verify chunking path used with map-reduce

    Follow RED-GREEN-REFACTOR: write failing tests first, then implement to pass.
  </implementation>
</feature>

<verification>
1. `npx vitest run src/services/__tests__/summarization.service.test.ts` -- all tests pass
2. `npx tsc --noEmit` -- no type errors
3. Tests cover: chunking edge cases (short/long/empty), cost calculation accuracy, batch estimation, chunking threshold detection
</verification>

<success_criteria>
- splitIntoChunks correctly splits with overlap, handles edge cases
- estimateCost produces accurate cost breakdowns with 10% buffer
- estimateBatchCost aggregates per-video estimates correctly
- summarizeVideo routes to direct or chunked processing based on token count
- All tests pass
- TypeScript compiles cleanly
</success_criteria>

<output>
After completion, create `.planning/phases/05-claude-summarization/05-02-SUMMARY.md`
</output>
